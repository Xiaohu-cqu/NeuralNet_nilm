{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xiaohu-cqu/NeuralNet_nilm/blob/master/seq2point_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VCLJ523QmUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "# This code is to train a neural network to perform energy disaggregation, \n",
        "# i.e., given a sequence of electricity mains reading, the algorithm\n",
        "# separates the mains into appliances.\n",
        "#\n",
        "# Inputs: mains windows -- find the window length in params_appliance\n",
        "# Targets: appliances windows -- \n",
        "#\n",
        "#\n",
        "# This code is written by Chaoyun Zhang and Mingjun Zhong.\n",
        "# Reference:\n",
        "# Chaoyun Zhang, Mingjun Zhong, Zongzuo Wang, Nigel Goddard, and Charles Sutton.\n",
        "# ``Sequence-to-point learning with neural networks for nonintrusive load monitoring.\" \n",
        "# Thirty-Second AAAI Conference on Articial Intelligence (AAAI-18), Feb. 2-7, 2018.\n",
        "############################################################\n",
        "\n",
        "import NetFlowExt as nf\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "import numpy as np\n",
        "import DataProvider\n",
        "import argparse\n",
        "\n",
        "# only one GPU is visible to current task.\n",
        "CUDA_VISIBLE_DEVICES=0 \n",
        "\n",
        "def remove_space(string):\n",
        "    return string.replace(\" \",\"\")\n",
        "    \n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description='Train a neural network\\\n",
        "                                     for energy disaggregation - \\\n",
        "                                     network input = mains window; \\\n",
        "                                     network target = the states of \\\n",
        "                                     the target appliance.')\n",
        "    parser.add_argument('--appliance_name', \n",
        "                        type=remove_space,\n",
        "                        default='kettle',\n",
        "                        help='the name of target appliance')\n",
        "    parser.add_argument('--datadir',\n",
        "                        type=str,\n",
        "                        default='../data/uk-dale/trainingdata/small/',\n",
        "                        help='this is the directory of the training samples')\n",
        "    parser.add_argument('--batchsize',\n",
        "                        type=int,\n",
        "                        default=1000,\n",
        "                        help='The batch size of training examples')\n",
        "    parser.add_argument('--n_epoch',\n",
        "                        type=int,\n",
        "                        default=50,\n",
        "                        help='The number of epoches.')\n",
        "    parser.add_argument('--save_model',\n",
        "                        type=int,\n",
        "                        default=-1,\n",
        "                        help='Save the learnt model: \\\n",
        "                            0 -- not to save the learnt model parameters;\\\n",
        "                            n (n>0) -- to save the model params every n steps;\\\n",
        "                            -1 -- only save the learnt model params \\\n",
        "                                    at the end of training.')\n",
        "    return parser.parse_args()\n",
        "\n",
        "# Units:\n",
        "# windowlength: number of data points\n",
        "# on_power_threshold,max_on_power: power\n",
        "#params_appliance = {'kettle':{'windowlength':129, \n",
        "#                              'on_power_threshold':2000, \n",
        "#                              'max_on_power':3948},\n",
        "#                    'microwave':{'windowlength':129,\n",
        "#                              'on_power_threshold':200,\n",
        "#                              'max_on_power':3138},\n",
        "#                    'fridge':{'windowlength':299,\n",
        "#                              'on_power_threshold':50,\n",
        "#                              'max_on_power':2572},\n",
        "#                    'dishwasher':{'windowlength':599,\n",
        "#                              'on_power_threshold':10,\n",
        "#                              'max_on_power':3230},\n",
        "#                    'washingmachine':{'windowlength':599,\n",
        "#                              'on_power_threshold':20,\n",
        "#                              'max_on_power':3962}}\n",
        "                              \n",
        "params_appliance = {'kettle':{'windowlength':599,\n",
        "                              'on_power_threshold':2000,\n",
        "                              'max_on_power':3998,\n",
        "                             'mean':700,\n",
        "                             'std':1000,\n",
        "                             's2s_length':128},\n",
        "                    'microwave':{'windowlength':599,\n",
        "                              'on_power_threshold':200,\n",
        "                              'max_on_power':3969,\n",
        "                                'mean':500,\n",
        "                                'std':800,\n",
        "                                's2s_length':128},\n",
        "                    'fridge':{'windowlength':599,\n",
        "                              'on_power_threshold':50,\n",
        "                              'max_on_power':3323,\n",
        "                             'mean':200,\n",
        "                             'std':400,\n",
        "                             's2s_length':512},\n",
        "                    'dishwasher':{'windowlength':599,\n",
        "                              'on_power_threshold':10,\n",
        "                              'max_on_power':3964,\n",
        "                                  'mean':700,\n",
        "                                  'std':1000,\n",
        "                                  's2s_length':1536},\n",
        "                    'washingmachine':{'windowlength':599,\n",
        "                              'on_power_threshold':20,\n",
        "                              'max_on_power':3999,\n",
        "                                      'mean':400,\n",
        "                                      'std':700,\n",
        "                                      's2s_length':2000}}\n",
        "                                      \n",
        "args = get_arguments()\n",
        "print args.appliance_name\n",
        "appliance_name = args.appliance_name\n",
        "def load_dataset():   \n",
        "    tra_x = args.datadir+args.appliance_name+'_mains_'+'tra_small' #save path for mains\n",
        "    val_x = args.datadir+args.appliance_name+'_mains_'+'val'\n",
        "\n",
        "    tra_y = args.datadir+args.appliance_name+'_'+'tra_small'+'_'+'pointnet'#save path for target\n",
        "    val_y = args.datadir+args.appliance_name+'_'+'val'+'_'+'pointnet'\n",
        "    \n",
        "    tra_set_x = np.load(tra_x+'.npy')  \n",
        "    tra_set_y = np.load(tra_y+'.npy')  \n",
        "    val_set_x = np.load(val_x+'.npy')  \n",
        "    val_set_y = np.load(val_y+'.npy')  \n",
        "    \n",
        "    print('training set:', tra_set_x.shape, tra_set_y.shape)\n",
        "    print('validation set:', val_set_x.shape, val_set_y.shape)\n",
        "    \n",
        "    return tra_set_x, tra_set_y, val_set_x,  val_set_y\n",
        "\n",
        "# load the data set\n",
        "tra_set_x, tra_set_y, val_set_x,  val_set_y = load_dataset()\n",
        "\n",
        "# get the window length of the training examples\n",
        "windowlength = params_appliance[args.appliance_name]['windowlength']\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "\n",
        "offset = int(0.5*(params_appliance[args.appliance_name]['windowlength']-1.0))\n",
        "\n",
        "tra_kwag = {\n",
        "    'inputs': tra_set_x, \n",
        "    'targets': tra_set_y,\n",
        "    'flatten':False}\n",
        "\n",
        "val_kwag = {\n",
        "    'inputs': val_set_x, \n",
        "    'targets': val_set_y,\n",
        "    'flatten':False}\n",
        "\n",
        "tra_provider = DataProvider.DoubleSourceSlider(batchsize = args.batchsize, \n",
        "                                                 shuffle = True, offset=offset)\n",
        "val_provider = DataProvider.DoubleSourceSlider(batchsize = 5000, \n",
        "                                                 shuffle = False, offset=offset)\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32, \n",
        "                   shape=[None, windowlength],\n",
        "                   name='x')\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 1], name='y_')\n",
        "\n",
        "network = tl.layers.InputLayer(x, name='input_layer')\n",
        "network = tl.layers.ReshapeLayer(network,\n",
        "                                 shape=(-1, windowlength, 1, 1))\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[10, 1, 1, 30],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn1')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[8, 1, 30, 30],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn2')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[6, 1, 30, 40],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn3')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[5, 1, 40, 50],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn4')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[5, 1, 50, 50],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn5')\n",
        "network = tl.layers.FlattenLayer(network,\n",
        "                                 name='flatten')\n",
        "\n",
        "# network = tl.layers.DenseLayer(network,\n",
        "#                                n_units=1024,\n",
        "#                                act = tf.nn.relu,\n",
        "#                                name='dense2')\n",
        "network = tl.layers.DenseLayer(network,\n",
        "                               n_units=1,\n",
        "                               act=tf.identity,\n",
        "                               name='output_layer')\n",
        "\n",
        "\n",
        "y = network.outputs\n",
        "cost = tl.cost.mean_squared_error(y, y_)\n",
        "train_params = network.all_params\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999,\n",
        "                            epsilon=1e-08, use_locking=False).minimize(cost, var_list=train_params)\n",
        "\n",
        "# initialize all variables\n",
        "#sess.run(tf.initialize_all_variables())\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# params = tl.files.load_npz(path='', name='cnn_lstm_model.npz')\n",
        "# tl.files.assign_params(sess, params, network)\n",
        "print 'set sucessful'\n",
        "\n",
        "save_path = './cnn'+appliance_name+'_pointnet_model'\n",
        "nf.customfit(sess = sess, \n",
        "             network = network, \n",
        "             cost = cost, \n",
        "             train_op = train_op, \n",
        "             tra_provider = tra_provider, \n",
        "             x = x, \n",
        "             y_ = y_, \n",
        "             acc=None, \n",
        "             n_epoch=args.n_epoch,\n",
        "             print_freq=1, \n",
        "             val_provider=val_provider, \n",
        "             save_model=args.save_model, \n",
        "             tra_kwag=tra_kwag, \n",
        "             val_kwag=val_kwag ,\n",
        "             save_path=save_path, \n",
        "             epoch_identifier=None,\n",
        "             earlystopping=True, \n",
        "             min_epoch=1,\n",
        "             patience=10)\n",
        "sess.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}