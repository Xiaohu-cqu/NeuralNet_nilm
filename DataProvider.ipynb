{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xiaohu-cqu/NeuralNet_nilm/blob/master/DataProvider.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VCLJ523QmUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class DoubleSourceSlider(object):\n",
        "\n",
        "    def __init__(self, batchsize, shuffle, offset):\n",
        "\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "        self.offset = offset\n",
        "\n",
        "    def feed(self, inputs, targets, flatten=True):\n",
        "\n",
        "        inputs, targets = inputs.flatten(), targets.flatten()\n",
        "        assert inputs.size == targets.size\n",
        "\n",
        "        max_batchsize = inputs.size - 2 * self.offset\n",
        "        if self.batchsize < 0:\n",
        "            self.batchsize = max_batchsize\n",
        "\n",
        "        indices = np.arange(max_batchsize)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start_idx in range(0, max_batchsize, self.batchsize):\n",
        "            excerpt = indices[start_idx:start_idx + self.batchsize]\n",
        "            if flatten:\n",
        "                yield np.array([inputs[idx:idx + 2 * self.offset + 1] for idx in excerpt]), \\\n",
        "                      targets[excerpt + self.offset]\n",
        "            else:\n",
        "                yield np.array([inputs[idx:idx + 2 * self.offset + 1] for idx in excerpt]), \\\n",
        "                      targets[excerpt + self.offset].reshape(-1, 1)\n",
        "\n",
        "    def generate_test_data(self, inputs, targets, targets_gt, offset, flatten=True):\n",
        "\n",
        "            shuffle = False\n",
        "            inputs, targets = inputs.flatten(), targets.flatten()\n",
        "            assert inputs.size == targets.size\n",
        "            max_batchsize = inputs.size - 2 * offset\n",
        "            batchsize = max_batchsize\n",
        "            #if self.batchsize < 0:\n",
        "            #    self.batchsize = max_batchsize\n",
        "    \n",
        "            indices = np.arange(max_batchsize)\n",
        "            if shuffle:\n",
        "                np.random.shuffle(indices)\n",
        "    \n",
        "            for start_idx in range(0, max_batchsize, batchsize):\n",
        "                excerpt = indices[start_idx:start_idx + batchsize]\n",
        "                if flatten:\n",
        "                    yield np.array([inputs[idx:idx + 2 * offset + 1] for idx in excerpt]), \\\n",
        "                          targets[excerpt + offset], \\\n",
        "                            targets_gt[excerpt + offset]\n",
        "                else:\n",
        "                    yield np.array([inputs[idx:idx + 2 * offset + 1] for idx in excerpt]), \\\n",
        "                          targets[excerpt + offset].reshape(-1, 1), \\\n",
        "                            targets_gt[excerpt + offset].reshape(-1, 1)\n",
        "\n",
        "\n",
        "class DoubleSourceSlider(object):\n",
        "    def __init__(self, batchsize, shuffle, offset):\n",
        "\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "        self.offset = offset\n",
        "\n",
        "    def feed(self, inputs, targets, flatten=True):\n",
        "\n",
        "        inputs, targets = inputs.flatten(), targets.flatten()\n",
        "        assert inputs.size == targets.size\n",
        "        max_batchsize = inputs.size - 2 * self.offset\n",
        "        if self.batchsize < 0:\n",
        "            self.batchsize = max_batchsize\n",
        "\n",
        "        indices = np.arange(max_batchsize)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start_idx in range(0, max_batchsize, self.batchsize):\n",
        "            excerpt = indices[start_idx:start_idx + self.batchsize]\n",
        "            if flatten:\n",
        "                yield np.array([inputs[idx:idx + 2 * self.offset + 1] for idx in excerpt]), \\\n",
        "                      targets[excerpt + self.offset]\n",
        "            else:\n",
        "                yield np.array([inputs[idx:idx + 2 * self.offset + 1] for idx in excerpt]), \\\n",
        "                      targets[excerpt + self.offset].reshape(-1, 1)\n",
        "\n",
        "\n",
        "class S2S_Slider(object):\n",
        "\n",
        "    def __init__(self, batchsize, shuffle, length):\n",
        "\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "        self.length = length\n",
        "\n",
        "    def feed(self, inputs, targets, flatten=True):\n",
        "\n",
        "        inputs, targets = inputs.flatten(), targets.flatten()\n",
        "        assert inputs.size == targets.size\n",
        "\n",
        "        max_batchsize = inputs.size - self.length\n",
        "        if self.batchsize < 0:\n",
        "            self.batchsize = max_batchsize\n",
        "\n",
        "        indices = np.arange(max_batchsize)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start_idx in range(0, max_batchsize, self.batchsize):\n",
        "            excerpt = indices[start_idx:start_idx + self.batchsize]\n",
        "            \n",
        "            yield np.array([inputs[idx:idx + self.length] for idx in excerpt]), \\\n",
        "                  np.array([targets[idx:idx + self.length] for idx in excerpt])\n",
        "\n",
        "    # def generate_test_data(self, inputs, targets, targets_gt, offset, flatten=True):\n",
        "    #\n",
        "    #     shuffle = False\n",
        "    #     inputs, targets = inputs.flatten(), targets.flatten()\n",
        "    #     assert inputs.size == targets.size\n",
        "    #     max_batchsize = inputs.size - 2 * offset\n",
        "    #     batchsize = max_batchsize\n",
        "    #     # if self.batchsize < 0:\n",
        "    #     #    self.batchsize = max_batchsize\n",
        "    #\n",
        "    #     indices = np.arange(max_batchsize)\n",
        "    #     if shuffle:\n",
        "    #         np.random.shuffle(indices)\n",
        "    #\n",
        "    #     for start_idx in range(0, max_batchsize, batchsize):\n",
        "    #         excerpt = indices[start_idx:start_idx + batchsize]\n",
        "    #         if flatten:\n",
        "    #             yield np.array([inputs[idx:idx + 2 * offset + 1] for idx in excerpt]), \\\n",
        "    #                   targets[excerpt + offset], \\\n",
        "    #                   targets_gt[excerpt + offset]\n",
        "    #         else:\n",
        "    #             yield np.array([inputs[idx:idx + 2 * offset + 1] for idx in excerpt]), \\\n",
        "    #                   targets[excerpt + offset].reshape(-1, 1), \\\n",
        "    #                   targets_gt[excerpt + offset].reshape(-1, 1)\n",
        "\n",
        "\n",
        "class MultiApp_Slider(object):\n",
        "\n",
        "    def __init__(self, batchsize, shuffle, offset):\n",
        "\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "        self.offset = offset\n",
        "\n",
        "    def feed(self, inputs, targets, flatten=True):\n",
        "\n",
        "        # inputs, targets = inputs.flatten(), targets.flatten()\n",
        "        inputs = inputs.flatten()\n",
        "\n",
        "        assert inputs.shape[0] == targets.shape[0]\n",
        "        max_batchsize = inputs.size - 2 * self.offset\n",
        "        if self.batchsize < 0:\n",
        "            self.batchsize = max_batchsize\n",
        "\n",
        "        indices = np.arange(max_batchsize)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start_idx in range(0, max_batchsize, self.batchsize):\n",
        "            excerpt = indices[start_idx:start_idx + self.batchsize]\n",
        "            # if flatten:\n",
        "            #     yield np.array([inputs[idx:idx + 2 * self.offset + 1] for idx in excerpt]), \\\n",
        "            #           targets[excerpt + self.offset]\n",
        "            # else:\n",
        "            yield np.array([inputs[idx:idx + 2 * self.offset + 1] for idx in excerpt]), \\\n",
        "                  targets[excerpt + self.offset, :]\n",
        "\n",
        "    # def generate_test_data(self, inputs, targets, targets_gt, offset, flatten=True):\n",
        "    #\n",
        "    #     shuffle = False\n",
        "    #     inputs, targets = inputs.flatten(), targets.flatten()\n",
        "    #     assert inputs.size == targets.size\n",
        "    #     max_batchsize = inputs.size - inputs.size - self.length\n",
        "    #     batchsize = max_batchsize\n",
        "    #     # if self.batchsize < 0:\n",
        "    #     #    self.batchsize = max_batchsize\n",
        "    #\n",
        "    #     indices = np.arange(max_batchsize)\n",
        "    #     if shuffle:\n",
        "    #         np.random.shuffle(indices)\n",
        "    #\n",
        "    #     for start_idx in range(0, max_batchsize, batchsize):\n",
        "    #         excerpt = indices[start_idx:start_idx + batchsize]\n",
        "    #         if flatten:\n",
        "    #             yield np.array([inputs[idx:idx + 2 * offset + 1] for idx in excerpt]), \\\n",
        "    #                   targets[excerpt + offset], \\\n",
        "    #                   targets_gt[excerpt + offset]\n",
        "    #         else:\n",
        "    #             yield np.array([inputs[idx:idx + 2 * offset + 1] for idx in excerpt]), \\\n",
        "    #                   targets[excerpt + offset].reshape(-1, 1), \\\n",
        "    #                   targets_gt[excerpt + offset].reshape(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DoubleSourceProvider(object):\n",
        "\n",
        "    def __init__(self, batchsize, shuffle):\n",
        "\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def feed(self, inputs, targets):\n",
        "        assert len(inputs) == len(targets)\n",
        "        if self.batchsize == -1:\n",
        "            self.batchsize = len(inputs)\n",
        "        if self.shuffle:\n",
        "            indices = np.arange(len(inputs))\n",
        "            np.random.shuffle(indices)\n",
        "        for start_idx in range(0, len(inputs) - self.batchsize + 1, self.batchsize):\n",
        "            if self.shuffle:\n",
        "                excerpt = indices[start_idx:start_idx + self.batchsize]\n",
        "            else:\n",
        "                excerpt = slice(start_idx, start_idx + self.batchsize)\n",
        "            yield inputs[excerpt], targets[excerpt]\n",
        "\n",
        "\n",
        "class Transformer(object):\n",
        "    \n",
        "    def __init__(self, mu, norm):\n",
        "        \n",
        "        self.mu = mu\n",
        "        self.norm = norm\n",
        "\n",
        "    def MuLawQuantisation(self, data, quantization=True):\n",
        "        \"\"\"\n",
        "        Perform the mu-law transformation\n",
        "        ------------------------------------------\n",
        "        :arg\n",
        "        data: data that needs to be transform\n",
        "        mu: scale\n",
        "        norm: normalisation constant\n",
        "        quantization: quantize to integral, default True\n",
        "\n",
        "        :return\n",
        "        The transformed data\n",
        "\n",
        "        \"\"\" \n",
        "        data = data.flatten()\n",
        "        data = data/self.norm\n",
        "\n",
        "        mu_law = np.sign(data)*(np.log(1+self.mu*np.abs(data))/np.log(1+self.mu))*self.mu\n",
        "\n",
        "        if quantization:\n",
        "            return np.round(mu_law)\n",
        "        else:\n",
        "            return mu_law\n",
        "\n",
        "    def InverseMuLaw(self, data, sample=False):\n",
        "        \"\"\"\n",
        "        Perform the inverse mu-law transformation\n",
        "        --------------------------------------------\n",
        "        :arg\n",
        "        data: data that needs to be inverse-transformed\n",
        "        mu: scale\n",
        "        norm: normalisation constant\n",
        "\n",
        "        :return\n",
        "        The inverse transformed data\n",
        "        \"\"\"     \n",
        "        if sample:        \n",
        "            means = data.flatten()\n",
        "            cov = np.eye(data.size)*sample        \n",
        "            data = np.random.multivariate_normal(means, cov)\n",
        "\n",
        "        self.mu = float(self.mu)\n",
        "        data /= self.mu\n",
        "\n",
        "        recover = np.sign(data)*(1/self.mu)*((1+self.mu)**np.abs(data)-1)\n",
        "\n",
        "        return recover*self.norm\n",
        "    \n",
        "    def LinearQuantisation(self, data, quantization=True):\n",
        "        \"\"\"\n",
        "        Perform the linear quantisation.\n",
        "        --------------------------------------\n",
        "        :arg\n",
        "        data: data that needs to be transform\n",
        "        mu: scale\n",
        "        norm: normalisation constant\n",
        "        quantization: quantize to integral, default True\n",
        "\n",
        "        :return\n",
        "        The transformed data\n",
        "\n",
        "        \"\"\" \n",
        "        data = data.flatten()\n",
        "        gap = int(self.norm/self.mu)\n",
        "\n",
        "        if quantization:\n",
        "            return np.round(data/gap)\n",
        "        else:\n",
        "            return data/gap\n",
        "        \n",
        "    def InverseLinear(self, data):\n",
        "        \"\"\"\n",
        "        Perform the inverse linear quantisation.\n",
        "        -------------------------------------\n",
        "        :arg\n",
        "        data: data that needs to be inverse-transformed\n",
        "        mu: scale\n",
        "        norm: normalisation constant\n",
        "\n",
        "        :return\n",
        "        The transformed data\n",
        "        \"\"\"     \n",
        "        return data*int(self.norm/self.mu)\n",
        "    \n",
        "    def Normalise(self, data):\n",
        "        \"\"\"\n",
        "        Perform the normalisation (data-mu)/norm.\n",
        "        --------------------------------------\n",
        "        :arg\n",
        "        data: data that needs to be transformed\n",
        "        mu: scale\n",
        "        norm: normlisation constant\n",
        "\n",
        "        :return\n",
        "        The normalized data\n",
        "\n",
        "        \"\"\"     \n",
        "        return (data-self.mu)/self.norm\n",
        "    \n",
        "    def InverseNormalise(self, data):\n",
        "        \"\"\"\n",
        "        Perform the in-normalisation data*norm+mu.\n",
        "        ------------------------------------------------\n",
        "        :arg\n",
        "        data: data that needs to be inverse-transformed\n",
        "        mu: scale\n",
        "        norm: normalisation constant\n",
        "        :return\n",
        "        The in-normalized data\n",
        "\n",
        "        \"\"\"  \n",
        "        \n",
        "        return data*self.norm+self.mu\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}