{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xiaohu-cqu/NeuralNet_nilm/blob/master/seq2seq_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VCLJ523QmUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "# This code is to train a neural network to perform energy disaggregation, \n",
        "# i.e., given a sequence of electricity mains reading, the algorithm\n",
        "# separates the mains into appliances.\n",
        "#\n",
        "# Inputs: mains windows -- find the window length in params_appliance\n",
        "# Targets: appliances windows -- \n",
        "#\n",
        "#\n",
        "# This code is written by Chaoyun Zhang and Mingjun Zhong.\n",
        "# Reference:\n",
        "# Chaoyun Zhang, Mingjun Zhong, Zongzuo Wang, Nigel Goddard, and Charles Sutton.\n",
        "# ``Sequence-to-point learning with neural networks for nonintrusive load monitoring.\" \n",
        "# Thirty-Second AAAI Conference on Articial Intelligence (AAAI-18), Feb. 2-7, 2018.\n",
        "############################################################\n",
        "\n",
        "import NetFlowExt as nf\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "import numpy as np\n",
        "import DataProvider\n",
        "import nilm_metric as nm\n",
        "from matplotlib.pylab import *\n",
        "\n",
        "def remove_space(string):\n",
        "    return string.replace(\" \",\"\")\n",
        "    \n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description='Predict the appliance\\\n",
        "                                     give a trained neural network\\\n",
        "                                     for energy disaggregation - \\\n",
        "                                     network input = mains window; \\\n",
        "                                     network target = the states of \\\n",
        "                                     the target appliance.')\n",
        "    parser.add_argument('--appliance_name', \n",
        "                        type=remove_space,\n",
        "                        default='kettle',\n",
        "                        help='the name of target appliance')\n",
        "    parser.add_argument('--datadir',\n",
        "                        type=str,\n",
        "                        default='../data/uk-dale/testdata/',\n",
        "                        help='this is the directory of the training samples')\n",
        "    parser.add_argument('--batchsize',\n",
        "                        type=int,\n",
        "                        default=1000,\n",
        "                        help='The batch size of training examples')\n",
        "    parser.add_argument('--n_epoch',\n",
        "                        type=int,\n",
        "                        default=1,\n",
        "                        help='The number of epoches.')\n",
        "    parser.add_argument('--nosOfWindows',\n",
        "                        type=int,\n",
        "                        default=100,\n",
        "                        help='The number of windows for prediction \\\n",
        "                        for each iteration.')\n",
        "    parser.add_argument('--save_model',\n",
        "                        type=int,\n",
        "                        default=-1,\n",
        "                        help='Save the learnt model: \\\n",
        "                            0 -- not to save the learnt model parameters;\\\n",
        "                            n (n>0) -- to save the model params every n steps;\\\n",
        "                            -1 -- only save the learnt model params \\\n",
        "                                    at the end of traing.')\n",
        "    return parser.parse_args()\n",
        "\n",
        "#params_appliance = {'kettle':{'windowlength':129,\n",
        "#                              'on_power_threshold':2000,\n",
        "#                              'max_on_power':3948},\n",
        "#                    'microwave':{'windowlength':129,\n",
        "#                              'on_power_threshold':200,\n",
        "#                              'max_on_power':3138},\n",
        "#                    'fridge':{'windowlength':299,\n",
        "#                              'on_power_threshold':50,\n",
        "#                              'max_on_power':2572},\n",
        "#                    'dishwasher':{'windowlength':599,\n",
        "#                              'on_power_threshold':10,\n",
        "#                              'max_on_power':3230},\n",
        "#                    'washingmachine':{'windowlength':599,\n",
        "#                              'on_power_threshold':20,\n",
        "#                              'max_on_power':3962}}\n",
        "                              \n",
        "params_appliance = {'kettle':{'windowlength':599,\n",
        "                              'on_power_threshold':2000,\n",
        "                              'max_on_power':3998,\n",
        "                             'mean':700,\n",
        "                             'std':1000,\n",
        "                             's2s_length':128},\n",
        "                    'microwave':{'windowlength':599,\n",
        "                              'on_power_threshold':200,\n",
        "                              'max_on_power':3969,\n",
        "                                'mean':500,\n",
        "                                'std':800,\n",
        "                                's2s_length':128},\n",
        "                    'fridge':{'windowlength':599,\n",
        "                              'on_power_threshold':50,\n",
        "                              'max_on_power':3323,\n",
        "                             'mean':200,\n",
        "                             'std':400,\n",
        "                             's2s_length':512},\n",
        "                    'dishwasher':{'windowlength':599,\n",
        "                              'on_power_threshold':10,\n",
        "                              'max_on_power':3964,\n",
        "                                  'mean':700,\n",
        "                                  'std':1000,\n",
        "                                  's2s_length':1536},\n",
        "                    'washingmachine':{'windowlength':599,\n",
        "                              'on_power_threshold':20,\n",
        "                              'max_on_power':3999,\n",
        "                                      'mean':400,\n",
        "                                      'std':700,\n",
        "                                      's2s_length':2000}}\n",
        "    \n",
        "args = get_arguments()\n",
        "def load_dataset():\n",
        "    app = args.datadir + args.appliance_name +'/' +'building2_'+ args.appliance_name\n",
        "    test_set_x = np.load(app+'_test_x.npy')  \n",
        "    test_set_y = np.load(app+'_test_y.npy')  \n",
        "    ground_truth = np.load(app+'_test_gt.npy')  \n",
        "    print('test set:', test_set_x.shape, test_set_y.shape)\n",
        "    print('testset path:{}'.format(app+'_test_gt.npy'))\n",
        "    print('testset path:{}'.format(app+'_test_x.npy'))\n",
        "    print('testset path:{}'.format(app+'_test_y.npy'))\n",
        "    \n",
        "    return test_set_x, test_set_y, ground_truth\n",
        "\n",
        "test_set_x, test_set_y, ground_truth = load_dataset()\n",
        "\n",
        "shuffle = False\n",
        "appliance_name = args.appliance_name\n",
        "mean = params_appliance[application]['mean']\n",
        "std = params_appliance[application]['std']\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "\n",
        "windowlength = params_appliance[args.appliance_name]['windowlength']\n",
        "\n",
        "offset = int(0.5*(params_appliance[application]['windowlength']-1.0))\n",
        "\n",
        "test_kwag = {\n",
        "    'inputs':test_set_x, \n",
        "    'targets':  ground_truth,\n",
        "    'flatten':False}\n",
        "\n",
        "# val_kwag = {\n",
        "#     'inputs': val_set_x, \n",
        "#     'targets': val_set_y,\n",
        "#     'flatten':False}\n",
        "\n",
        "test_provider = DataProvider.MultiApp_Slider(batchsize = batchsize, \n",
        "                                                 shuffle = False, offset=offset)\n",
        "# val_provider = DataProvider.DoubleSourceSlider(batchsize = 5000, \n",
        "#                                                  shuffle = False, offset=offset)\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32, \n",
        "                   shape=[None, windowlength],\n",
        "                   name='x')\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 1], name='y_')\n",
        "\n",
        "\n",
        "\n",
        "##### cnn2\n",
        "network = tl.layers.InputLayer(x, name='input_layer')\n",
        "network = tl.layers.ReshapeLayer(network, \n",
        "                                 shape=(-1, windowlength, 1, 1))\n",
        "network = tl.layers.Conv2dLayer(network,  \n",
        "                                act = tf.nn.relu, \n",
        "                                shape = [10, 1, 1, 30],\n",
        "                                strides=[1, 1, 1, 1],  \n",
        "                                padding='SAME', \n",
        "                                name = 'cnn1')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act = tf.nn.relu,\n",
        "                                shape = [8, 1, 30, 30],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name = 'cnn2')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act = tf.nn.relu,\n",
        "                                shape = [6, 1, 30, 40],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name = 'cnn3')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act = tf.nn.relu,\n",
        "                                shape = [5, 1, 40, 50],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name = 'cnn4')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act = tf.nn.relu,\n",
        "                                shape = [5, 1, 50, 50],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name = 'cnn5')\n",
        "# network = tl.layers.Conv2dLayer(network,\n",
        "#                                 act = tf.nn.relu,\n",
        "#                                 shape = [5, 1, 50, 60],\n",
        "#                                 strides=[1, 1, 1, 1],\n",
        "#                                 padding='SAME',\n",
        "#                                 name = 'cnn6')\n",
        "network = tl.layers.FlattenLayer(network,\n",
        "                                 name='flatten')\n",
        "network = tl.layers.DenseLayer(network, \n",
        "                               n_units=1024, \n",
        "                               act = tf.nn.relu, \n",
        "                               name='dense2')\n",
        "network = tl.layers.DenseLayer(network, \n",
        "                               n_units=windowlength,\n",
        "                               act =tf.identity,\n",
        "                               name='output_layer')\n",
        "\n",
        "y = network.outputs\n",
        "param_file = 'cnn'+app2+'_s2s_model_check.npz'\n",
        "print(param_file)\n",
        "#params = tl.files.load_npz(path='./', name=param_file)\n",
        "params = tl.files.load_npz(path='', name=param_file)\n",
        "tl.files.assign_params(sess, params, network)\n",
        "print('params done')\n",
        "\n",
        "test_prediction = nf.custompredict_add(sess=sess,\n",
        "                                   network=network, \n",
        "                                   output_provider = test_provider , \n",
        "                                   x = x, \n",
        "                                   fragment_size=window_size, \n",
        "                                   output_length=windowlength, \n",
        "                                   y_op=None, \n",
        "                                   out_kwag=test_kwag,\n",
        "                                  seqlength = test_set_x.size, std = std, mean = mean)\n",
        "\n",
        "max_power = params_appliance[application]['max_on_power']\n",
        "threshold = params_appliance[application]['on_power_threshold']\n",
        "\n",
        "\n",
        "ground_truth = ground_truth[offset:-offset]*std+mean\n",
        "mains = (test_set_x[offset:-offset])*std+mean\n",
        "\n",
        "prediction = test_prediction[offset:-offset]\n",
        "prediction[prediction<=0.0] = 0.0\n",
        "print(prediction.shape)\n",
        "print(ground_truth.shape)\n",
        "# np.save(args.appliance_name.replace(\" \",\"_\")+'_prediction', prediction)\n",
        "# to load results: np.load(args.appliance_name+'_prediction')\n",
        "sess.close()\n",
        "sample_second = 6.0 # sample time is 6 seconds\n",
        "print('F1:{0}'.format(nm.get_F1(ground_truth.flatten(), prediction.flatten(), threshold)))\n",
        "print('NDE:{0}'.format(nm.get_nde(ground_truth.flatten(), prediction.flatten())))\n",
        "print('MAE:{0}'.format(nm.get_abs_error(ground_truth.flatten(), prediction.flatten())))\n",
        "print('SAE:{0}'.format(nm.get_sae(ground_truth.flatten(), prediction.flatten(), sample_second)))\n",
        "save_name_y_pred = 'results/'+'pointnet_building2_'+args.appliance_name+'_pred.npy' #save path for mains\n",
        "save_name_y_gt = 'results/'+'pointnet_building2_'+args.appliance_name+'_gt.npy'#save path for target\n",
        "save_name_mains = 'results/'+'pointnet_building2_'+args.appliance_name+'_mains.npy'#save path for target\n",
        "np.save(save_name_y_pred, prediction)\n",
        "np.save(save_name_y_gt,ground_truth)\n",
        "np.save(save_name_mains,mains)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}