{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xiaohu-cqu/NeuralNet_nilm/blob/master/seq2point_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VCLJ523QmUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python2\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Feb  6 15:08:11 2017\n",
        "\n",
        "@author: mzhong\n",
        "\"\"\"\n",
        "\n",
        "#!/usr/bin/env python2\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Dec  1 15:00:27 2016\n",
        "\n",
        "############################################################\n",
        "# This code is to train a neural network to perform energy disaggregation, \n",
        "# i.e., given a sequence of electricity mains reading, the algorithm\n",
        "# separates the mains into appliances.\n",
        "#\n",
        "# Inputs: mains windows -- find the window length in params_appliance\n",
        "# Targets: appliances windows -- \n",
        "#\n",
        "#\n",
        "# This code is written by Chaoyun Zhang and Mingjun Zhong.\n",
        "# Reference:\n",
        "# Chaoyun Zhang, Mingjun Zhong, Zongzuo Wang, Nigel Goddard, and Charles Sutton.\n",
        "# ``Sequence-to-point learning with neural networks for nonintrusive load monitoring.\" \n",
        "# Thirty-Second AAAI Conference on Articial Intelligence (AAAI-18), Feb. 2-7, 2018.\n",
        "############################################################\n",
        "\"\"\"\n",
        "\n",
        "import NetFlowExt as nf\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "import numpy as np\n",
        "import DataProvider\n",
        "import argparse\n",
        "import nilm_metric as nm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def remove_space(string):\n",
        "    return string.replace(\" \",\"\")\n",
        "    \n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description='Predict the appliance\\\n",
        "                                     give a trained neural network\\\n",
        "                                     for energy disaggregation - \\\n",
        "                                     network input = mains window; \\\n",
        "                                     network target = the states of \\\n",
        "                                     the target appliance.')\n",
        "    parser.add_argument('--appliance_name', \n",
        "                        type=remove_space,\n",
        "                        default='kettle',\n",
        "                        help='the name of target appliance')\n",
        "    parser.add_argument('--datadir',\n",
        "                        type=str,\n",
        "                        default='../data/uk-dale/testdata/',\n",
        "                        help='this is the directory of the training samples')\n",
        "    parser.add_argument('--batchsize',\n",
        "                        type=int,\n",
        "                        default=1000,\n",
        "                        help='The batch size of training examples')\n",
        "    parser.add_argument('--n_epoch',\n",
        "                        type=int,\n",
        "                        default=1,\n",
        "                        help='The number of epoches.')\n",
        "    parser.add_argument('--nosOfWindows',\n",
        "                        type=int,\n",
        "                        default=100,\n",
        "                        help='The number of windows for prediction \\\n",
        "                        for each iteration.')\n",
        "    parser.add_argument('--save_model',\n",
        "                        type=int,\n",
        "                        default=-1,\n",
        "                        help='Save the learnt model: \\\n",
        "                            0 -- not to save the learnt model parameters;\\\n",
        "                            n (n>0) -- to save the model params every n steps;\\\n",
        "                            -1 -- only save the learnt model params \\\n",
        "                                    at the end of traing.')\n",
        "    return parser.parse_args()\n",
        "\n",
        "#params_appliance = {'kettle':{'windowlength':129,\n",
        "#                              'on_power_threshold':2000,\n",
        "#                              'max_on_power':3948},\n",
        "#                    'microwave':{'windowlength':129,\n",
        "#                              'on_power_threshold':200,\n",
        "#                              'max_on_power':3138},\n",
        "#                    'fridge':{'windowlength':299,\n",
        "#                              'on_power_threshold':50,\n",
        "#                              'max_on_power':2572},\n",
        "#                    'dishwasher':{'windowlength':599,\n",
        "#                              'on_power_threshold':10,\n",
        "#                              'max_on_power':3230},\n",
        "#                    'washingmachine':{'windowlength':599,\n",
        "#                              'on_power_threshold':20,\n",
        "#                              'max_on_power':3962}}\n",
        "                              \n",
        "params_appliance = {'kettle':{'windowlength':599,\n",
        "                              'on_power_threshold':2000,\n",
        "                              'max_on_power':3998,\n",
        "                             'mean':700,\n",
        "                             'std':1000,\n",
        "                             's2s_length':128},\n",
        "                    'microwave':{'windowlength':599,\n",
        "                              'on_power_threshold':200,\n",
        "                              'max_on_power':3969,\n",
        "                                'mean':500,\n",
        "                                'std':800,\n",
        "                                's2s_length':128},\n",
        "                    'fridge':{'windowlength':599,\n",
        "                              'on_power_threshold':50,\n",
        "                              'max_on_power':3323,\n",
        "                             'mean':200,\n",
        "                             'std':400,\n",
        "                             's2s_length':512},\n",
        "                    'dishwasher':{'windowlength':599,\n",
        "                              'on_power_threshold':10,\n",
        "                              'max_on_power':3964,\n",
        "                                  'mean':700,\n",
        "                                  'std':1000,\n",
        "                                  's2s_length':1536},\n",
        "                    'washingmachine':{'windowlength':599,\n",
        "                              'on_power_threshold':20,\n",
        "                              'max_on_power':3999,\n",
        "                                      'mean':400,\n",
        "                                      'std':700,\n",
        "                                      's2s_length':2000}}\n",
        "    \n",
        "args = get_arguments()\n",
        "def load_dataset():\n",
        "    app = args.datadir + args.appliance_name +'/' +'building2_'+ args.appliance_name\n",
        "    test_set_x = np.load(app+'_test_x.npy')  \n",
        "    test_set_y = np.load(app+'_test_y.npy')  \n",
        "    ground_truth = np.load(app+'_test_gt.npy')  \n",
        "    print('test set:', test_set_x.shape, test_set_y.shape)\n",
        "    print('testset path:{}'.format(app+'_test_gt.npy'))\n",
        "    print('testset path:{}'.format(app+'_test_x.npy'))\n",
        "    print('testset path:{}'.format(app+'_test_y.npy'))\n",
        "    \n",
        "    return test_set_x, test_set_y, ground_truth\n",
        "\n",
        "test_set_x, test_set_y, ground_truth = load_dataset()\n",
        "\n",
        "shuffle = False\n",
        "windowlength = params_appliance[args.appliance_name]['windowlength']\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "test_kwag = {\n",
        "    'inputs': test_set_x, \n",
        "    'targets': test_set_y}\n",
        "\n",
        "\n",
        "test_provider = DataProvider.DoubleSourceProvider(batchsize = -1, \n",
        "                                                 shuffle = False)\n",
        "\n",
        "x = tf.placeholder(tf.float32, \n",
        "                   shape=[None, 1, windowlength],\n",
        "                   name='x')\n",
        "y_ = tf.placeholder(tf.int64, shape=[None, 1], name='y_')\n",
        "\n",
        "network = tl.layers.InputLayer(x, name='input_layer')\n",
        "network = tl.layers.ReshapeLayer(network,\n",
        "                                 shape=(-1, windowlength, 1, 1))\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[10, 1, 1, 30],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn1')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[8, 1, 30, 30],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn2')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[6, 1, 30, 40],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn3')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[5, 1, 40, 50],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn4')\n",
        "network = tl.layers.Conv2dLayer(network,\n",
        "                                act=tf.nn.relu,\n",
        "                                shape=[5, 1, 50, 50],\n",
        "                                strides=[1, 1, 1, 1],\n",
        "                                padding='SAME',\n",
        "                                name='cnn5')\n",
        "network = tl.layers.FlattenLayer(network,\n",
        "                                 name='flatten')\n",
        "network = tl.layers.DenseLayer(network,\n",
        "                               n_units=1024,\n",
        "                               act = tf.nn.relu,\n",
        "                               name='dense2')\n",
        "network = tl.layers.DenseLayer(network,\n",
        "                               n_units=1,\n",
        "                               act=tf.identity,\n",
        "                               name='output_layer')\n",
        "\n",
        "y = network.outputs\n",
        "\n",
        "\n",
        "train_params = network.all_params\n",
        "sess.run(tf.initialize_all_variables())\n",
        "\n",
        "param_file = 'cnn'+args.appliance_name+'_pointnet_model.npz'\n",
        "params = tl.files.load_npz(path='', name=param_file)\n",
        "tl.files.assign_params(sess, params, network)\n",
        "\n",
        "test_prediction = nf.custompredict(sess=sess, \n",
        "                                   network=network, \n",
        "                                   output_provider = test_provider , \n",
        "                                   x = x, \n",
        "                                   fragment_size=args.nosOfWindows, \n",
        "                                   output_length=1, \n",
        "                                   y_op=None, \n",
        "                                   out_kwag=test_kwag)\n",
        "\n",
        "max_power = params_appliance[args.appliance_name]['max_on_power']\n",
        "threshold = params_appliance[args.appliance_name]['on_power_threshold']\n",
        "mean = params_appliance[args.appliance_name]['mean']\n",
        "std = params_appliance[args.appliance_name]['std'] \n",
        "\n",
        "prediction = test_prediction[0]*std+mean\n",
        "prediction[prediction<=0.0] = 0.0\n",
        "print(prediction.shape)\n",
        "print(ground_truth.shape)\n",
        "# np.save(args.appliance_name.replace(\" \",\"_\")+'_prediction', prediction)\n",
        "# to load results: np.load(args.appliance_name+'_prediction')\n",
        "sess.close()\n",
        "sample_second = 6.0 # sample time is 6 seconds\n",
        "print('F1:{0}'.format(nm.get_F1(ground_truth.flatten(), prediction.flatten(), threshold)))\n",
        "print('NDE:{0}'.format(nm.get_nde(ground_truth.flatten(), prediction.flatten())))\n",
        "print('MAE:{0}'.format(nm.get_abs_error(ground_truth.flatten(), prediction.flatten())))\n",
        "print('SAE:{0}'.format(nm.get_sae(ground_truth.flatten(), prediction.flatten(), sample_second)))\n",
        "\n",
        "## save the prediction to files\n",
        "#save_name_y_pred = 'results/'+'pointnet_building2_'+args.appliance_name+'_pred.npy' #save path for mains\n",
        "#save_name_y_gt = 'results/'+'pointnet_building2_'+args.appliance_name+'_gt.npy'#save path for target\n",
        "#np.save(save_name_y_pred, prediction.flatten())\n",
        "#np.save(save_name_y_gt,ground_truth.flatten())\n",
        "\n",
        "# save the prediction to files\n",
        "mean = params_appliance[args.appliance_name]['mean']\n",
        "std = params_appliance[args.appliance_name]['std']\n",
        "offset = int(0.5*(params_appliance[args.appliance_name]['windowlength']-1.0))\n",
        "savemains = test_set_x[offset:,0,0].flatten()*std + mean\n",
        "savegt = ground_truth.flatten()\n",
        "savepred = prediction.flatten()\n",
        "\n",
        "save_name_y_pred = 'results/'+'pointnet_building2_'+args.appliance_name+'_pred.npy' #save path for mains\n",
        "save_name_y_gt = 'results/'+'pointnet_building2_'+args.appliance_name+'_gt.npy'#save path for target\n",
        "save_name_mains = 'results/'+'pointnet_building2_'+args.appliance_name+'_mains.npy'#save path for target\n",
        "np.save(save_name_y_pred, savepred)\n",
        "np.save(save_name_y_gt,savegt)\n",
        "np.save(save_name_mains,savemains)\n",
        "print('size: x={0}, y={0}, gt={0}'.format(np.shape(savemains), np.shape(savepred), np.shape(savegt)))\n",
        "\n",
        "plt.plot(savemains,color='k',linewidth=3.0)\n",
        "plt.plot(ground_truth,color='r',linewidth=2.0)\n",
        "plt.plot(prediction,color='b',linewidth=1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}